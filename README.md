# SiLLM - Silicon LLM Training & Inference
SiLLM simplifies the process of training and running Large Language Models (LLMs) on Apple Silicon by leveraging the [MLX](https://github.com/ml-explore/mlx/) framework. Building upon the foundation provided by the [MLX Examples](https://github.com/ml-explore/mlx-examples), this project introduces additional features specifically designed to enhance LLM operations with MLX.

## Roadmap
- Save model to transformers format
- MoE training
- Phi support
- Qwen support
- Repetition penalty
- Learning rate schedulers